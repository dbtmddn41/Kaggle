{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61446,"databundleVersionId":6962461,"sourceType":"competition"},{"sourceId":7567728,"sourceType":"datasetVersion","datasetId":4395544},{"sourceId":150248402,"sourceType":"kernelVersion"},{"sourceId":161694219,"sourceType":"kernelVersion"},{"sourceId":161869578,"sourceType":"kernelVersion"}],"dockerImageVersionId":30648,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch as tc \nimport torch.nn as nn  \nimport numpy as np\nfrom tqdm import tqdm\nfrom torch.cuda.amp import autocast\nimport cv2\nimport os,sys\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport pandas as pd\n!python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch\nimport segmentation_models_pytorch as smp\n# !python -m pip install /kaggle/input/ttach003/ttach-0.0.3-py3-none-any.whl\n# import ttach as tta\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.parallel import DataParallel\nfrom dotenv import load_dotenv","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/nvidia/ tensorrt\n# import os, tensorrt\n# os.environ[\"LD_LIBRARY_PATH\"] = \"/opt/conda/lib/python3.10/site-packages/tensorrt/\"\n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/torch2trt/ torch2trt\n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/torch2trt/ nvidia-pyindex\n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/torch2trt/ onnx-graphsurgeon\n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/torch2trt/ onnxruntime","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1_path_i = 0    # 12 #9 # 7 #5 #in_chans_1__25     3 in_chans_1__20 2 \n#model_path_i9 = 12  # 9 #11\nmodel2_path_i = 4\n\nclass CFG:\n# ============== model CFG =============\n    model_name = 'Unet'\n    backbone1 = 'se_resnext50_32x4d'\n    in_chans1 = 1 #5 # 65\n    \n    backbone2 = 'timm-efficientnet-b2'\n    in_chans2 = 1 #5 # 65\n    \n    ensemble_weight = 0.9\n    #============== tta cfg =============\n    num_rot90=4\n    num_flip=0\n    #============== _ CFG =============\n    image_size = 1024 #512\n    input_size= 1024 #512\n    tile_size = image_size\n    stride = tile_size // 4\n    drop_egde_pixel= 0 # 16 #32\n    \n    target_size = 1\n    chopping_percentile=1e-3\n    # ============== fold =============\n    valid_id = 1\n    batch=16 #128\n\n    th_percentile_i = 4\n    th_percentile_list = [0.0013099, 0.0013499, 0.0013999, 0.0014499,   0.00143 ]\n\n    th_percentile = th_percentile_list[th_percentile_i] #0.00143 #0.00145 #0.00146 #0.00149 #0.00145 # 0.0014 #0.00175 #0.0021\n    \n    #axis_w = [0.3353333 ,0.3323333,0.3323333 ]\n    model_path=[\n        \"/kaggle/input/sennet-hoa-trt-models/model9.pth\",\n        \"/kaggle/input/sennet-hoa-trt-models/model18.pth\",\n        \"/kaggle/input/sennet-hoa-tensorrt/model19.pth\",\n        \"/kaggle/input/sennet-hoa-trt-models/model22.pth\",\n        \"/kaggle/input/sennet-hoa-trt-models/model27.pth\",\n    ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UnetModel(nn.Module):\n    def __init__(self, backbone, in_chans, target_size, weight):\n        super().__init__()\n        self.model = smp.Unet( #FPN\n            encoder_name=backbone, \n            encoder_weights=weight,\n            in_channels=in_chans,\n            classes=target_size,\n            activation=None,\n        )\n    def forward(self, x):\n        output = self.model(x)\n        return output[:, 0]\nclass UnetPlusPlusModel(nn.Module):\n    def __init__(self, backbone, in_chans, target_size, weight):\n        super().__init__()\n        self.model = smp.UnetPlusPlus( #FPN\n            encoder_name=backbone, \n            encoder_weights=weight,\n            in_channels=in_chans,\n            classes=target_size,\n            activation=None,\n        )\n    def forward(self, x):\n        output = self.model(x)\n        return output[:, 0]\nclass FPNModel(nn.Module):\n    def __init__(self, backbone, in_chans, target_size, weight):\n        super().__init__()\n        self.model = smp.FPN( #FPN\n            encoder_name=backbone, \n            encoder_weights=weight,\n            in_channels=in_chans,\n            classes=target_size,\n            activation=None,\n        )\n    def forward(self, x):\n        output = self.model(x)\n        return output[:, 0]\n\nclass EnsembleModel(nn.Module):\n    def __init__(self, CFG, weight1=None, weight2=None):\n        super().__init__()\n        self.CFG = CFG        \n        self.model1 = UnetModel(backbone=CFG.backbone1,\n                                in_chans=CFG.in_chans1,\n                                target_size=CFG.target_size,\n                                weight=weight1)\n        self.model2 = UnetModel(backbone=CFG.backbone2,\n                                in_chans=CFG.in_chans2,\n                                target_size=CFG.target_size,\n                                weight=weight2)\n        self.batch=CFG.batch\n        self.ensemble_weight = CFG.ensemble_weight\n    \n    def forward(self,x:tc.Tensor):\n        #x.shape=(batch,c,h,w)\n        x=x.to(tc.float32)\n        x=norm_with_clip(x.reshape(-1,*x.shape[2:])).reshape(x.shape)\n        \n        if CFG.input_size!=CFG.image_size:\n            x=nn.functional.interpolate(x,size=(CFG.input_size,CFG.input_size),mode='bilinear',align_corners=True)\n        \n        shape=x.shape\n        x=[tc.rot90(x,k=i,dims=(-2,-1)) for i in range(CFG.num_rot90)]\n        x.extend([tc.flip(x[i], dims=(-1,)) for i in range(CFG.num_flip)])\n\n        x=tc.cat(x,dim=0)\n        with autocast():\n            with tc.no_grad():\n                x1=[self.model1(x[i*self.batch:(i+1)*self.batch]) for i in range((x.shape[0]-1)//self.batch+1)]\n                # batch=64,64...48\n                x1=tc.cat(x1,dim=0)\n                \n                x2=[self.model2(x[i*self.batch:(i+1)*self.batch]) for i in range((x.shape[0]-1)//self.batch+1)]\n                # batch=64,64...48\n                x2=tc.cat(x2,dim=0)\n        x1=x1.sigmoid()\n        x1=x1.reshape(CFG.num_rot90+CFG.num_flip,shape[0],*shape[2:])\n        x1_=[tc.rot90(x1[i],k=-i,dims=(-2,-1)) for i in range(CFG.num_rot90)]\n        x1_.extend([tc.rot90(tc.flip(x1[i+4], dims=(-1,)),k=-i,dims=(-2,-1)) for i in range(CFG.num_flip)])\n        x1=tc.stack(x1_,dim=0).mean(0)\n        \n        \n        x2=x2.sigmoid()\n        x2=x2.reshape(CFG.num_rot90+CFG.num_flip,shape[0],*shape[2:])\n        x2_=[tc.rot90(x2[i],k=-i,dims=(-2,-1)) for i in range(CFG.num_rot90)]\n        x2_.extend([tc.rot90(tc.flip(x2[i+4], dims=(-1,)),k=-i,dims=(-2,-1)) for i in range(CFG.num_flip)])\n        x2=tc.stack(x2_,dim=0).mean(0)\n        \n        x = x1*self.ensemble_weight + x2*(1-self.ensemble_weight)\n        if CFG.input_size!=CFG.image_size:\n            x=nn.functional.interpolate(x[None],size=(CFG.image_size,CFG.image_size),mode='bilinear',align_corners=True)[0]\n        return x\n\n\ndef build_model(weight1=None, weight2=None):\n    load_dotenv()\n\n    print('model_name', CFG.model_name)\n    print('backbone1', CFG.backbone1)\n    print('backbone2', CFG.backbone2)\n\n\n    model = EnsembleModel(CFG, weight1, weight2)\n\n    return model.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_1024(img , image_size = 1024):\n    if image_size > img.shape[1]:\n       img = np.rot90(img)\n       start1 = (CFG.image_size - img.shape[0])//2 \n       top =     img[0                    : start1,   0: img.shape[1] ]\n       bottom  = img[img.shape[0] -start1 : img.shape[0],   0 : img.shape[1] ]\n       img_result = np.concatenate((top,img,bottom ),axis=0)\n       img_result = np.rot90(img_result)\n       img_result = np.rot90(img_result)\n       img_result = np.rot90(img_result)\n    else :\n       img_result = img\n    return img_result\n\ndef to_1024_no_rot(img, image_size = 1024):\n    if image_size > img.shape[0]:  \n       start1 = ( image_size - img.shape[0])//2\n       top =     img[0                    : start1,   0: img.shape[1] ]\n       bottom  = img[img.shape[0] -start1 : img.shape[0],   0 : img.shape[1] ]\n       img_result = np.concatenate((top,img,bottom ),axis=0)\n    else: \n       img_result = img\n    return img_result\n\ndef to_1024_1024(img  , image_size = 1024 ):\n     img_result = to_1024(img, image_size )\n     return img_result\n    \ndef to_original ( im_after, img, image_size = 1024 ):\n    top_ = 0\n    left_ = 0\n    if (im_after.shape[0] > img.shape[0]):\n             top_  = ( image_size - img.shape[0])//2 \n    if    (im_after.shape[1] > img.shape[1]) :\n             left_  = ( image_size - img.shape[1])//2  \n    if (top_>0)or (left_>0) :\n             img_result = im_after[top_  : img.shape[0] + top_,   left_: img.shape[1] + left_ ]\n    else:\n             img_result = im_after\n    return img_result  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(mask):\n    pixel = mask.flatten()\n    pixel = np.concatenate([[0], pixel, [0]])\n    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n    run[1::2] -= run[::2]\n    rle = ' '.join(str(r) for r in run)\n    if rle == '':\n        rle = '1 0'\n    return rle\n\ndef min_max_normalization(x:tc.Tensor)->tc.Tensor:\n    \"\"\"input.shape=(batch,f1,...)\"\"\"\n    shape=x.shape\n    if x.ndim>2:\n        x=x.reshape(x.shape[0],-1)\n    \n    min_=x.min(dim=-1,keepdim=True)[0]\n    max_=x.max(dim=-1,keepdim=True)[0]\n    if min_.mean()==0 and max_.mean()==1:\n        return x.reshape(shape)\n    \n    x=(x-min_)/(max_-min_+1e-9)\n    return x.reshape(shape)\n\ndef norm_with_clip(x:tc.Tensor,smooth=1e-5):\n    dim=list(range(1,x.ndim))\n    mean=x.mean(dim=dim,keepdim=True)\n    std=x.std(dim=dim,keepdim=True)\n    x=(x-mean)/(std+smooth)\n    x[x>5]=(x[x>5]-5)*1e-3 +5\n    x[x<-3]=(x[x<-3]+3)*1e-3-3\n    return x\n\nclass Data_loader(Dataset):\n    def __init__(self,path,s=\"/images/\"):\n        self.paths=glob(path+f\"{s}*.tif\")\n        self.paths.sort()\n        self.bool=s==\"/labels/\"\n    \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self,index):\n        img=cv2.imread(self.paths[index],cv2.IMREAD_GRAYSCALE)\n        img = to_1024_1024(img , image_size = CFG.image_size )\n        \n        img=tc.from_numpy(img.copy())\n        if self.bool:\n            img=img.to(tc.bool)\n        else:\n            img=img.to(tc.uint8)\n        return img\n\ndef load_data(path,s):\n    data_loader=Data_loader(path,s)\n    data_loader=DataLoader(data_loader, batch_size=16, num_workers=2)\n    data=[]\n    for x in tqdm(data_loader):\n        data.append(x)\n    x=tc.cat(data,dim=0)\n    ########################################################################\n    TH=x.reshape(-1).numpy()\n    index = -int(len(TH) * CFG.chopping_percentile)\n    TH:int = np.partition(TH, index)[index]\n    x[x>TH]=int(TH)\n    ########################################################################\n    TH=x.reshape(-1).numpy()\n    index = -int(len(TH) * CFG.chopping_percentile)\n    TH:int = np.partition(TH, -index)[-index]\n    x[x<TH]=int(TH)\n    ########################################################################\n    #x=(min_max_normalization(x.to(tc.float16))*255).to(tc.uint8)\n    return x\n\nclass Pipeline_Dataset(Dataset):\n    def __init__(self,x,path):\n        self.img_paths  = glob(path+\"/images/*\")\n        self.img_paths.sort()\n        self.in_chan = CFG.in_chans1\n        z=tc.zeros(self.in_chan//2,*x.shape[1:],dtype=x.dtype)\n        self.x=tc.cat((z,x,z),dim=0)\n        \n    def __len__(self):\n        return self.x.shape[0]-self.in_chan+1\n    \n    def __getitem__(self, index):\n        x  = self.x[index:index+self.in_chan]\n        return x,index\n    \n    def get_mark(self,index):\n        id=self.img_paths[index].split(\"/\")[-3:]\n        id.pop(1)\n        id=\"_\".join(id)\n        return id[:-4]\n    \n    def get_marks(self):\n        ids=[]\n        for index in range(len(self)):\n            ids.append(self.get_mark(index))\n        return ids\n\ndef add_edge(x:tc.Tensor,edge:int):\n    #x=(C,H,W)\n    #output=(C,H+2*edge,W+2*edge)\n    mean_=int(x.to(tc.float32).mean())\n    x=tc.cat([x,tc.ones([x.shape[0],edge,x.shape[2]],dtype=x.dtype,device=x.device)*mean_],dim=1)\n    x=tc.cat([x,tc.ones([x.shape[0],x.shape[1],edge],dtype=x.dtype,device=x.device)*mean_],dim=2)\n    x=tc.cat([tc.ones([x.shape[0],edge,x.shape[2]],dtype=x.dtype,device=x.device)*mean_,x],dim=1)\n    x=tc.cat([tc.ones([x.shape[0],x.shape[1],edge],dtype=x.dtype,device=x.device)*mean_,x],dim=2)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch2trt import TRTModule\nimport torch\nmodel1_trt = TRTModule()\nmodel2_trt = TRTModule()\n\nmodel1_trt.load_state_dict(torch.load(CFG.model_path[ model1_path_i ]))\nmodel2_trt.load_state_dict(torch.load(CFG.model_path[ model2_path_i ]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=build_model(   )\nmodel.model1 = model1_trt.cuda()\nmodel.model2 = model2_trt.cuda()\n\nmodel.eval()\n# model=DataParallel(model)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_output(debug=False):\n    outputs=[]\n    \n    if debug:\n        paths=[\"/kaggle/input/blood-vessel-segmentation/train/kidney_2\"]\n    else:\n        paths=glob(\"/kaggle/input/blood-vessel-segmentation/test/*\")\n    outputs=[[],[]]\n    for path in paths:\n        x=load_data(path,\"/images/\")\n        labels=tc.zeros_like(x,dtype=tc.uint8)\n        mark=Pipeline_Dataset(x,path).get_marks()\n        \n        \n        for axis in [0,1,2]:\n            debug_count=0\n            if axis==0:\n                x_=x\n                labels_=labels\n            elif axis==1:\n                x_=x.permute(1,2,0)\n                labels_=labels.permute(1,2,0)\n            elif axis==2:\n                x_=x.permute(2,0,1)\n                labels_=labels.permute(2,0,1)\n            if x.shape[0]==3 and axis!=0:\n                break\n            dataset=Pipeline_Dataset(x_,path)\n            dataloader=DataLoader(dataset,batch_size=1,shuffle=False,num_workers=1)\n            shape=dataset.x.shape[-2:]\n            x1_list = np.arange(0, shape[0]+CFG.tile_size-CFG.tile_size+1, CFG.stride)\n            y1_list = np.arange(0, shape[1]+CFG.tile_size-CFG.tile_size+1, CFG.stride)\n            for img,index in tqdm(dataloader):\n                #img=(1,C,H,W)\n                img=img.to(\"cuda:0\")\n                img=add_edge(img[0],CFG.tile_size//2)[None]\n\n                mask_pred = tc.zeros_like(img[:,0],dtype=tc.float32,device=img.device)\n                mask_count = tc.zeros_like(img[:,0],dtype=tc.float32,device=img.device)\n\n                indexs=[]\n                chip=[]\n                for y1 in y1_list:\n                    for x1 in x1_list:\n                        x2 = x1 + CFG.tile_size\n                        y2 = y1 + CFG.tile_size\n                        indexs.append([x1+CFG.drop_egde_pixel,x2-CFG.drop_egde_pixel,\n                                       y1+CFG.drop_egde_pixel,y2-CFG.drop_egde_pixel])\n                        chip.append(img[...,x1:x2,y1:y2])\n\n                y_preds = model.forward(tc.cat(chip)).to(device=0)\n                \n                \n                if CFG.drop_egde_pixel:\n                    y_preds=y_preds[...,CFG.drop_egde_pixel:-CFG.drop_egde_pixel,\n                                        CFG.drop_egde_pixel:-CFG.drop_egde_pixel]\n                for i,(x1,x2,y1,y2) in enumerate(indexs):\n                    mask_pred[...,x1:x2, y1:y2] += y_preds[i]\n                    mask_count[...,x1:x2, y1:y2] += 1\n\n                mask_pred /= mask_count\n\n                #Rrecover\n                mask_pred=mask_pred[...,CFG.tile_size//2:-CFG.tile_size//2,CFG.tile_size//2:-CFG.tile_size//2]\n                \n                labels_[index]+=(mask_pred[0]*255 /3 ).to(tc.uint8).cpu()\n                if debug:\n                    debug_count+=1\n                    plt.subplot(121)\n                    plt.imshow(img[0,CFG.in_chans1//2].cpu().detach().numpy())\n                    plt.subplot(122)\n                    plt.imshow(mask_pred[0].cpu().detach().numpy())\n                    plt.show()\n                    if debug_count>3:\n                        break\n        outputs[0].append(labels)\n        outputs[1].extend(mark)\n    return outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"is_submit=len(glob(\"/kaggle/input/blood-vessel-segmentation/test/kidney_5/images/*.tif\"))!=3\n#is_submit=True\noutput,ids=get_output(not is_submit)\n\n\n####################################\nTH=[x.flatten().numpy() for x in output]\nTH=np.concatenate(TH)\nindex = -int(len(TH) * CFG.th_percentile)\nTH:int = np.partition(TH, index)[index]\nprint(TH)\n\nimg=cv2.imread(\"/kaggle/input/blood-vessel-segmentation/test/kidney_5/images/0001.tif\",cv2.IMREAD_GRAYSCALE)\n\n####################################\nsubmission_df=[]\ndebug_count=0\nfor index in range(len(ids)):\n    id=ids[index]\n    i=0\n    for x in output:\n        if index>=len(x):\n            index-=len(x)\n            i+=1\n        else:\n            break\n    mask_pred=(output[i][index]>TH).numpy()\n    \n    mask_pred2 = to_original ( mask_pred, img, image_size = 1024 )\n    mask_pred =  mask_pred2.copy()\n    \n    ####################################\n    if not is_submit:\n        plt.subplot(121)\n        plt.imshow(mask_pred)\n        plt.show()\n        debug_count+=1\n        if debug_count>6:\n            break\n        \n    rle = rle_encode(mask_pred)\n    \n    submission_df.append(\n        pd.DataFrame(data={\n            'id'  : id,\n            'rle' : rle,\n        },index=[0])\n    )\n\nsubmission_df =pd.concat(submission_df)\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df.head(6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntc.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
