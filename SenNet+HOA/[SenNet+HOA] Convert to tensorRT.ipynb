{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7322239,"sourceType":"datasetVersion","datasetId":4249424,"isSourceIdPinned":true},{"sourceId":7351547,"sourceType":"datasetVersion","datasetId":4265818},{"sourceId":7540433,"sourceType":"datasetVersion","datasetId":4340200,"isSourceIdPinned":true},{"sourceId":161694219,"sourceType":"kernelVersion"}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation_models_pytorch \n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/nvidia/ tensorrt\n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/torch2trt/ torch2trt\n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/torch2trt/ nvidia-pyindex\n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/torch2trt/ onnx-graphsurgeon\n%pip install --no-index --find-links /kaggle/input/install-nvidia-tensorrt/torch2trt/ onnxruntime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-06T04:36:14.972008Z","iopub.execute_input":"2024-02-06T04:36:14.972500Z","iopub.status.idle":"2024-02-06T04:38:36.166348Z","shell.execute_reply.started":"2024-02-06T04:36:14.972415Z","shell.execute_reply":"2024-02-06T04:38:36.165279Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting segmentation_models_pytorch\n  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.16.2)\nCollecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting timm==0.9.2 (from segmentation_models_pytorch)\n  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (4.66.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (9.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.2)\nCollecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.24.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.31.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.12.2)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (21.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.11.17)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\nDownloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=0dd7136e30b61196abc44d35f7e8e2635b690c592e208ce5b4e3b78d9d2531a3\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=53a756f7a4c5810dc27f7d2a45bb3f5baf9ed04ecb504fb42318d815a9d650c4\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 0.9.12\n    Uninstalling timm-0.9.12:\n      Successfully uninstalled timm-0.9.12\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\nLooking in links: /kaggle/input/install-nvidia-tensorrt/nvidia/\nProcessing /kaggle/input/install-nvidia-tensorrt/nvidia/tensorrt-8.6.1.post1-py2.py3-none-any.whl\nProcessing /kaggle/input/install-nvidia-tensorrt/nvidia/tensorrt_libs-8.6.1-py2.py3-none-manylinux_2_17_x86_64.whl (from tensorrt)\nProcessing /kaggle/input/install-nvidia-tensorrt/nvidia/tensorrt_bindings-8.6.1-cp310-none-manylinux_2_17_x86_64.whl (from tensorrt)\nProcessing /kaggle/input/install-nvidia-tensorrt/nvidia/nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (from tensorrt-libs==8.6.1->tensorrt)\nProcessing /kaggle/input/install-nvidia-tensorrt/nvidia/nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (from tensorrt-libs==8.6.1->tensorrt)\nProcessing /kaggle/input/install-nvidia-tensorrt/nvidia/nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (from tensorrt-libs==8.6.1->tensorrt)\nProcessing /kaggle/input/install-nvidia-tensorrt/nvidia/nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (from nvidia-cudnn-cu12->tensorrt-libs==8.6.1->tensorrt)\nInstalling collected packages: tensorrt-bindings, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cublas-cu12, nvidia-cudnn-cu12, tensorrt-libs, tensorrt\nSuccessfully installed nvidia-cublas-cu12-12.3.4.1 nvidia-cuda-nvrtc-cu12-12.3.107 nvidia-cuda-runtime-cu12-12.3.101 nvidia-cudnn-cu12-8.9.7.29 tensorrt-8.6.1.post1 tensorrt-bindings-8.6.1 tensorrt-libs-8.6.1\nNote: you may need to restart the kernel to use updated packages.\nLooking in links: /kaggle/input/install-nvidia-tensorrt/torch2trt/\nProcessing /kaggle/input/install-nvidia-tensorrt/torch2trt/torch2trt-0.4.0-py3-none-any.whl\nInstalling collected packages: torch2trt\nSuccessfully installed torch2trt-0.4.0\nNote: you may need to restart the kernel to use updated packages.\nLooking in links: /kaggle/input/install-nvidia-tensorrt/torch2trt/\nProcessing /kaggle/input/install-nvidia-tensorrt/torch2trt/nvidia_pyindex-1.0.9-py3-none-any.whl\nInstalling collected packages: nvidia-pyindex\nSuccessfully installed nvidia-pyindex-1.0.9\nNote: you may need to restart the kernel to use updated packages.\nLooking in links: /kaggle/input/install-nvidia-tensorrt/torch2trt/\nProcessing /kaggle/input/install-nvidia-tensorrt/torch2trt/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from onnx-graphsurgeon) (1.24.4)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from onnx-graphsurgeon) (1.15.0)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx->onnx-graphsurgeon) (3.20.3)\nInstalling collected packages: onnx-graphsurgeon\nSuccessfully installed onnx-graphsurgeon-0.3.27\nNote: you may need to restart the kernel to use updated packages.\nLooking in links: /kaggle/input/install-nvidia-tensorrt/torch2trt/\nProcessing /kaggle/input/install-nvidia-tensorrt/torch2trt/onnxruntime-1.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\nProcessing /kaggle/input/install-nvidia-tensorrt/torch2trt/coloredlogs-15.0.1-py2.py3-none-any.whl (from onnxruntime)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.24.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.12)\nProcessing /kaggle/input/install-nvidia-tensorrt/torch2trt/humanfriendly-10.0-py2.py3-none-any.whl (from coloredlogs->onnxruntime)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime) (3.1.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\nInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorrt\nfrom torch2trt import torch2trt\nfrom torch import nn\nimport torch as tc\nfrom dotenv import load_dotenv\nimport segmentation_models_pytorch as smp\nfrom torch.cuda.amp import autocast","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:38:36.168250Z","iopub.execute_input":"2024-02-06T04:38:36.168541Z","iopub.status.idle":"2024-02-06T04:38:43.309543Z","shell.execute_reply.started":"2024-02-06T04:38:36.168512Z","shell.execute_reply":"2024-02-06T04:38:43.308612Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class CFG:\n# ============== model CFG =============\n    model_name = 'Unet'\n    backbone1 = 'se_resnext50_32x4d'\n    in_chans1 = 1 #5 # 65\n    \n    backbone2 = 'inceptionresnetv2'\n    in_chans2 = 1 #5 # 65\n    \n    model1_path = '/kaggle/input/sn-hoa-8e-5-27-rot0-5/se_resnext50_32x4d_26_loss0.10_score0.90_val_loss0.12_val_score0.88_midd_1024.pt'\n    model2_path = '/kaggle/input/sennet-hoa-models/unet_inceptionresnetv2_41_loss0.05_score0.89_val_loss0.24_val_score0.82_midd_1024_final.pt'\n    ensemble_weight = 0.7\n    num_rot90=4\n    num_flip=4\n    \n    target_size = 1\n    image_size = 1024 #512\n    input_size= 1024 #512\n    \n    batch=32","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:46:30.393085Z","iopub.execute_input":"2024-02-06T04:46:30.393964Z","iopub.status.idle":"2024-02-06T04:46:30.399428Z","shell.execute_reply.started":"2024-02-06T04:46:30.393931Z","shell.execute_reply":"2024-02-06T04:46:30.398390Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def rle_encode(mask):\n    pixel = mask.flatten()\n    pixel = np.concatenate([[0], pixel, [0]])\n    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n    run[1::2] -= run[::2]\n    rle = ' '.join(str(r) for r in run)\n    if rle == '':\n        rle = '1 0'\n    return rle\n\ndef min_max_normalization(x:tc.Tensor)->tc.Tensor:\n    \"\"\"input.shape=(batch,f1,...)\"\"\"\n    shape=x.shape\n    if x.ndim>2:\n        x=x.reshape(x.shape[0],-1)\n    \n    min_=x.min(dim=-1,keepdim=True)[0]\n    max_=x.max(dim=-1,keepdim=True)[0]\n    if min_.mean()==0 and max_.mean()==1:\n        return x.reshape(shape)\n    \n    x=(x-min_)/(max_-min_+1e-9)\n    return x.reshape(shape)\n\ndef norm_with_clip(x:tc.Tensor,smooth=1e-5):\n    dim=list(range(1,x.ndim))\n    mean=x.mean(dim=dim,keepdim=True)\n    std=x.std(dim=dim,keepdim=True)\n    x=(x-mean)/(std+smooth)\n    x[x>5]=(x[x>5]-5)*1e-3 +5\n    x[x<-3]=(x[x<-3]+3)*1e-3-3\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:46:31.081134Z","iopub.execute_input":"2024-02-06T04:46:31.081474Z","iopub.status.idle":"2024-02-06T04:46:31.091979Z","shell.execute_reply.started":"2024-02-06T04:46:31.081446Z","shell.execute_reply":"2024-02-06T04:46:31.091112Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class UnetModel(nn.Module):\n    def __init__(self, backbone, in_chans, target_size, weight):\n        super().__init__()\n        self.model = smp.Unet( #FPN\n            encoder_name=backbone, \n            encoder_weights=weight,\n            in_channels=in_chans,\n            classes=target_size,\n            activation=None,\n        )\n    def forward(self, x):\n        output = self.model(x)\n        return output[:, 0]\nclass UnetPlusPlusModel(nn.Module):\n    def __init__(self, backbone, in_chans, target_size, weight):\n        super().__init__()\n        self.model = smp.UnetPlusPlus( #FPN\n            encoder_name=backbone, \n            encoder_weights=weight,\n            in_channels=in_chans,\n            classes=target_size,\n            activation=None,\n        )\n    def forward(self, x):\n        output = self.model(x)\n        return output[:, 0]\nclass FPNModel(nn.Module):\n    def __init__(self, backbone, in_chans, target_size, weight):\n        super().__init__()\n        self.model = smp.FPN( #FPN\n            encoder_name=backbone, \n            encoder_weights=weight,\n            in_channels=in_chans,\n            classes=target_size,\n            activation=None,\n        )\n    def forward(self, x):\n        output = self.model(x)\n        return output[:, 0]\n\nclass EnsembleModel(nn.Module):\n    def __init__(self, CFG, weight1=None, weight2=None):\n        super().__init__()\n        self.CFG = CFG        \n        self.model1 = UnetModel(backbone=CFG.backbone1,\n                                in_chans=CFG.in_chans1,\n                                target_size=CFG.target_size,\n                                weight=weight1)\n        self.model2 = UnetModel(backbone=CFG.backbone2,\n                                in_chans=CFG.in_chans2,\n                                target_size=CFG.target_size,\n                                weight=weight2)\n        self.batch=CFG.batch\n        self.ensemble_weight = CFG.ensemble_weight\n    \n    def forward(self,x:tc.Tensor):\n        #x.shape=(batch,c,h,w)\n        x=x.to(tc.float32)\n        x=norm_with_clip(x.reshape(-1,*x.shape[2:])).reshape(x.shape)\n        \n        if CFG.input_size!=CFG.image_size:\n            x=nn.functional.interpolate(x,size=(CFG.input_size,CFG.input_size),mode='bilinear',align_corners=True)\n        \n        shape=x.shape\n        x=[tc.rot90(x,k=i,dims=(-2,-1)) for i in range(CFG.num_rot90)]\n        x.extend([tc.flip(x[i], dims=(-1,)) for i in range(CFG.num_flip)])\n\n        x=tc.cat(x,dim=0)\n        with autocast():\n            with tc.no_grad():\n                x1=[self.model1(x[i*self.batch:(i+1)*self.batch]) for i in range(x.shape[0]//self.batch+1)]\n                # batch=64,64...48\n                x1=tc.cat(x1,dim=0)\n                \n                x2=[self.model2(x[i*self.batch:(i+1)*self.batch]) for i in range(x.shape[0]//self.batch+1)]\n                # batch=64,64...48\n                x2=tc.cat(x2,dim=0)\n        x1=x1.sigmoid()\n        x1=x1.reshape(CFG.num_rot90+CFG.num_flip,shape[0],*shape[2:])\n        x1_=[tc.rot90(x1[i],k=-i,dims=(-2,-1)) for i in range(CFG.num_rot90)]\n        x1_.extend([tc.rot90(tc.flip(x1[i+4], dims=(-1,)),k=-i,dims=(-2,-1)) for i in range(CFG.num_flip)])\n        x1=tc.stack(x1_,dim=0).mean(0)\n        \n        \n        x2=x2.sigmoid()\n        x2=x2.reshape(CFG.num_rot90+CFG.num_flip,shape[0],*shape[2:])\n        x2_=[tc.rot90(x2[i],k=-i,dims=(-2,-1)) for i in range(CFG.num_rot90)]\n        x2_.extend([tc.rot90(tc.flip(x2[i+4], dims=(-1,)),k=-i,dims=(-2,-1)) for i in range(CFG.num_flip)])\n        x2=tc.stack(x2_,dim=0).mean(0)\n        \n        x = x1*self.ensemble_weight + x2*(1-self.ensemble_weight)\n        if CFG.input_size!=CFG.image_size:\n            x=nn.functional.interpolate(x[None],size=(CFG.image_size,CFG.image_size),mode='bilinear',align_corners=True)[0]\n        return x\n\n\ndef build_model(weight1=None, weight2=None):\n    load_dotenv()\n\n    print('model_name', CFG.model_name)\n    print('backbone1', CFG.backbone1)\n    print('backbone2', CFG.backbone2)\n\n\n    model = EnsembleModel(CFG, weight1, weight2)\n\n    return model.cuda()","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:46:31.652973Z","iopub.execute_input":"2024-02-06T04:46:31.653278Z","iopub.status.idle":"2024-02-06T04:46:31.679724Z","shell.execute_reply.started":"2024-02-06T04:46:31.653250Z","shell.execute_reply":"2024-02-06T04:46:31.678946Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model=build_model()\nmodel.model1.load_state_dict(tc.load(CFG.model1_path,\"cpu\"))\nmodel.model2.load_state_dict(tc.load(CFG.model2_path,\"cpu\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:46:32.150196Z","iopub.execute_input":"2024-02-06T04:46:32.150480Z","iopub.status.idle":"2024-02-06T04:46:33.950979Z","shell.execute_reply.started":"2024-02-06T04:46:32.150457Z","shell.execute_reply":"2024-02-06T04:46:33.950077Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"model_name Unet\nbackbone1 se_resnext50_32x4d\nbackbone2 inceptionresnetv2\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"x = tc.zeros(1, 1, 1024,1024).to('cuda')\n# model1_trt = torch2trt(model.model1, [x], use_onnx=True, fp16_mode=True, max_batch_size=16, max_workspace_size=int(1.2e+10))\nmodel2_trt = torch2trt(model.model2, [x], use_onnx=True, fp16_mode=True, max_batch_size=16, max_workspace_size=int(1.2e+10))","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:46:33.952661Z","iopub.execute_input":"2024-02-06T04:46:33.952975Z","iopub.status.idle":"2024-02-06T04:48:04.920711Z","shell.execute_reply.started":"2024-02-06T04:46:33.952951Z","shell.execute_reply":"2024-02-06T04:48:04.919673Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:16: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if h % output_stride != 0 or w % output_stride != 0:\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nmodel_pth = 'model27.pth'\n# torch.save(model1_trt.state_dict(), model_pth)\ntorch.save(model2_trt.state_dict(), model_pth)","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:48:04.922899Z","iopub.execute_input":"2024-02-06T04:48:04.923582Z","iopub.status.idle":"2024-02-06T04:48:07.371248Z","shell.execute_reply.started":"2024-02-06T04:48:04.923548Z","shell.execute_reply":"2024-02-06T04:48:07.370451Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch2trt import TRTModule\n\nmodel_trt = TRTModule()\n\nmodel_trt.load_state_dict(torch.load(model_pth))","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:48:07.372766Z","iopub.execute_input":"2024-02-06T04:48:07.373075Z","iopub.status.idle":"2024-02-06T04:48:09.082515Z","shell.execute_reply.started":"2024-02-06T04:48:07.373048Z","shell.execute_reply":"2024-02-06T04:48:09.081584Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nx = torch.zeros(1,1,1024,1024).cuda()\nmodel_trt(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
